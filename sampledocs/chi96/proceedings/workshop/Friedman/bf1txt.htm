<HTML><HEAD>
<TITLE>User Autonomy: Who Should Control What and 
When?</TITLE>
</HEAD>

<BODY>
<TABLE WIDTH="100%" >
<TR>
<TD valign="top"><IMG SRC="./../../graphics/logo_a.JPG" ALT="Logo A" HEIGHT=25 WIDTH=256><A HREF="../../index.htm"><IMG SRC="./../../graphics/home.JPG" ALT="Home" BORDER=0 HEIGHT=25 WIDTH=98></A><BR><IMG SRC="./../../graphics/logo_b.JPG" ALT="Logo B" HEIGHT=25 WIDTH=256><A HREF="../../indexes.htm"><IMG SRC="./../../graphics/index.JPG" ALT="Index" BORDER=0 HEIGHT=25 WIDTH=98></A><BR><IMG SRC="./../../graphics/logo_c.JPG" ALT="Logo C" HEIGHT=24 WIDTH=256><A HREF="../../acmcopy.htm"><IMG SRC="./../../graphics/acmcopy.JPG" ALT="ACM Copy" BORDER=0 HEIGHT=24 WIDTH=98></A>
<p><IMG SRC="./../../graphics/workshop.JPG" ALT="workshop" HEIGHT=35 WIDTH=249><A HREF="../../workshop.htm"><IMG SRC="./../../graphics/toc.JPG" ALT="Table of Contents" BORDER=0 HEIGHT=35 WIDTH=105></A>
</TD>
</TR>
</TABLE>
<HR width="100%">

<H1>User Autonomy: Who Should Control What and 
When? </H1>
<P>

<em>Batya Friedman*, Helen Nissenbaum**</em>
<p>

<dl>
<dt>*Mathematics and Computer Science<BR>
<dt>Colby College<BR>
<dt>Waterville, ME  04901,  USA<BR>
<dt>+1 207 872 3572<BR>
<dt>b_friedm@colby.edu<P>
</dl>
<p>
<dl>
<dt>**University Center for Human Values<BR>
<dt>Marx Hall<BR>
<dt>Princeton University<BR>
<dt>Princeton, NJ  08544,  USA<BR>
<dt>+1 609 258 2879<BR>
<dt>helen@phoenix.princeton.edu</CENTER><P>
</dl>
<p>
<hr>

<H3>KEYWORDS</H3>
Autonomy, computer system design, design methods, ethics, 
information systems, social computing, social impact.<P>

<H2>INTRODUCTION</H2>
In this workshop we are concerned with understanding the 
relationship between user autonomy, the user interface, and 
computer system design.  By autonomy we mean the capability to act 
on the basis of one's own decisions; to be guided by 
one's own reasons, desires, and goals.  When actions are unduly 
constrained or restricted then autonomy may be diminished or 
violated.  Evaluating the interface and system design in relation to 
user autonomy involves uncovering the extent to which 
systems either enhance or diminish autonomy.<P>

A case in point:  This past year, a colleague of ours (whom we will 
call Jim) enthusiastically welcomed video-conferencing 
into his office.  With the addition of a video camera, microphone, and 
a few other things Jim was poised for real-time 
interactions with colleagues in far away places.  Jim got down to 
work -- connected with his colleagues.  The technology was 
terrific.  But when the first session was over, Jim was horrified.  
There was no on/off switch on the video camera.  How 
could he know if someone was looking in?  There was no on/off 
switch on the microphone.  How could he know if someone 
was listening in?  In self-defense, Jim attached a 3X5 index card to 
the top of his video camera; he can flip the card down to 
cover the camera lens whenever he wants to insure visual privacy.  
Gaining control over his microphone was a bit tougher; 
Jim has sewn a small felt bag to cover the microphone and mute the 
sound.<P>

This example from video-conferencing begins to highlight the 
importance for users to have control over the technology they 
use.  More generally, the example points to the larger issue of user 
autonomy.<P>

This workshop builds on the organizers' previous work on designing 
computer systems for responsible computer use [1, 2, 
3, 4].  In the workshop, we draw on the organizers' background and 
participants' research and design experiences (1) to 
identify positive designs and abuses of user autonomy in computer 
systems and (2) to generate design principles for 
protecting user autonomy in the design of future systems.<P>

<H2>WORKSHOP GOALS</H2>
<UL>
<LI>To explore with colleagues the meaning and value of user 
autonomy, the nature of the relationship between user 
autonomy and control of computer systems, and the elements of 
interface and system design that affect user 
autonomy.<P>

<LI>To provide a forum (opportunity) for colleagues to discuss issues 
of user autonomy in computer systems that have 
arisen from their own design experiences.<P>

<LI>To work with colleagues to identify positive designs and abuses 
of user autonomy in computer systems.<P>

<LI>To work with colleagues to generate design principles for 
protecting user autonomy in the design of future systems.<P>
</UL>

<H2>REFERENCES</H2>
<OL>
<LI>Friedman, B., & Millett, L.  (1995, May).  &quot;It's the 
computer's fault&quot; -- Reasoning about computers as 
moral agents.  Conference companion of the conference on Human 
Factors in Computing Systems, CHI '95 (pp. 226-
227).  New York: Association for Computing Machinery.<P>

<LI>Friedman, B., & Nissenbaum, H.  (in press).  Bias in computer 
systems.  ACM Transactions on Information 
Systems.<P>

<LI>Friedman, B., & Nissenbaum, H.  (1995, May).  Workshop at CHI 
'95: Minimizing bias in computer systems.  
Conference companion of the conference on Human Factors in 
Computing Systems, CHI '95 (p. 444).  New York: 
Association for Computing Machinery.<P>

<LI>Nissenbaum, H.  (1994).  Computing and accountability.  
Communications of the ACM, 37(1), 72-80.<P>
</OL>
<H3><CENTER>(c) Copyright held by the authors.</CENTER><P></H3>
<P>
<ADDRESS>
User Autonomy: Who Should Control What and When?<BR>
b_friedm@colby.edu<BR>
</address>
</BODY>
