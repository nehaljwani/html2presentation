<HTML>
<HEAD>
<TITLE>The Representation of Agents: Anthropomorphism, Agency, and 
</TITLE>

</HEAD>
<BODY>
<TABLE WIDTH="100%" >
<TR>
<TD valign="top"><IMG SRC="./../../graphics/logo_a.JPG" ALT="Logo A" HEIGHT=25 WIDTH=256><A HREF="../../index.htm"><IMG SRC="./../../graphics/home.JPG" ALT="Home" BORDER=0 HEIGHT=25 WIDTH=98></A><BR><IMG SRC="./../../graphics/logo_b.JPG" ALT="Logo B" HEIGHT=25 WIDTH=256><A HREF="../../indexes.htm"><IMG SRC="./../../graphics/index.JPG" ALT="Index" BORDER=0 HEIGHT=25 WIDTH=98></A><BR><IMG SRC="./../../graphics/logo_c.JPG" ALT="Logo C" HEIGHT=24 WIDTH=256><A HREF="../../acmcopy.htm"><IMG SRC="./../../graphics/acmcopy.JPG" ALT="ACM Copy" BORDER=0 HEIGHT=24 WIDTH=98></A>
<p><IMG SRC="./../../graphics/shortpap.JPG" ALT="shortpap" HEIGHT=35 WIDTH=249><A HREF="../../shortpap.htm"><IMG SRC="./../../graphics/toc.JPG" ALT="Table of Contents" BORDER=0 HEIGHT=35 WIDTH=105></A>
</TD>
</TR>
</TABLE>
<HR width="100%">

<H1>The Representation of Agents:</H1>
<H1>Anthropomorphism, Agency, and Intelligence<BR>
</H1>
<P>
<EM>William Joseph King*, Jun Ohya**<BR>
</EM>
<P>
*Human Interface Technology Laboratory
<P>
Fluke Hall; FJ-15
<P>
University of Washington
<P>
Seattle, Washington 98195, USA
<P>
jking@hitl.washington.edu<BR>
<BR>
<P>
**Communication Systems Research Laboratories
<P>
Advanced Telecommunications Research Institute
<P>
Seika-cho, Soraku-gun
<P>
Kyoto, 619-02, Japan
<P>
ohya@atr-sw.atr.co.jp
<HR>
<H2>ABSTRACT</H2>
<P>
<FONT COLOR=#000000>Agents have become a predominat area of research
and development in human interfaces. A major issue in the development
of these agents is how to represent them and their activities
to the user. Anthropomorphic forms have been suggested, since
they provide a great degree of subtlety and afford social interaction.
However, these forms may be problematic since they may be inherently
interpretted as having a high degree of agency and intelligence.
An experiment is presented which supports these contentions. 
<BR>
</FONT>
<H3>KEYWORDS: </H3>
<P>
<FONT COLOR=#000000>agents, anthropomorphism, facial expression,
user interface design<BR>
</FONT>
<H2>INTRODUCTION</H2>
<P>
<FONT COLOR=#000000>In recent years, research into autonomous
agents has increased dramatically. These agents are meant to carry
out tasks for the user and serve as another layer of mediation
within the system [1]. This layer of mediation employs artificial
intelligence techniques to make decisions and to take certain
actions within the system. This proactive agent acts autonomously
or with permission from the user; therefore, it relieves the user
of the burden of having to carry out tedious or repetitive actions
[1,2].</FONT>
<P>
<FONT COLOR=#000000>A&nbsp;great challenge in designing the human
interface to a system using autonomous agents is representing
the state of the agents. On can assume that the user probably
needs to know, at some high level of granularity, a number of
specifics about the agent&iacute;s operations. These specifics
may include the stage the agent is at within a task, the certainty
the agent has of its own decisions within the task, and the movement
toward the goal of finishing the task. One can also assume that,
at the highest level, the user simply needs to know how much trust
to invest in the agent.</FONT>
<P>
<FONT COLOR=#000000>Trust, in this situation, is the relative
ability level which the human user attributes to a certain software
entity. Learning theory would indicate that this level of trust
may be developed over time through the user&iacute;s observation
of the success and failure of a given agent. However, this may
take quite a long time since many agents depend upon establishing
a history of the user&iacute;s actions and preferences to achieve
their optimum performance [2]. In the short term, especially during
the initial exposures of the user to the agent, the interface
will have to provide some other information to aid the user in
appraising the agent.</FONT>
<P>
<FONT COLOR=#000000>Anthropomorphic representations for agents
have been suggested [1, 3, 4, 5]. The reasoning behind this suggestion
is that the anthropomorphic representation allows for a rich set
of easily identifiable behaviors and for social interaction. However,
these representations do not tend to afford a quick assessment
of the agent&iacute;s capabilities, especially during initial
exposure to the agent. If anything, these representations may
make the agent seem more intelligent, capable of a higher level
of agency, and more trustworthy than it actually is. Empirical
data are necessary to make any conclusive statements.<BR>
</FONT>
<H2>SUBJECTS</H2>
<P>
<FONT COLOR=#000000>Eighteen adult subjects participated in the
experiment. The subject pool was chosen to represent a range of
expertise in the use of computers; however, none of the subjects
had prior exposure to this experimental system. Half of the subjects
were from &icirc;Western&#148; philosophical traditions and half
of the subjects were from &icirc;Eastern&#148; philosophical traditions.
Half of the subjects were male.<BR>
</FONT>
<H2>REPRESENTATIONS</H2>
<P>
<FONT COLOR=#000000>Twenty stimuli were chosen for the experiment..
These stimuli ranged from simple geometric shapes (e.g., sphere)
to three dimensional, fully articulated human forms. The set included
Chernoff faces, with both positive and negative facial expressions,
and stylized facial caricatures. It included very high resolution
human forms in two and three dimensions and in wire frame. Some
of the faces exhibited random eye blinking. The set also included
a variety of non-facial forms of equal geometric complexity to
balance the experiment. Each of the 20 stimuli was presented both
static and dynamic. In the dynamic presentation, the stimuli would
move into the subject&iacute;s field of view from above until
it reached the center of the display. <BR>
</FONT>
<H2>MEASURES</H2>
<P>
<FONT COLOR=#000000>The measure used in this experiment was a
questionnaire containing 40 sets (stimuli were presented in two
different conditions) of three questions. The first question was
a multi-dimensional scale developed to assess the type of phenomena
which was presented. The scale was composed of a triangle with
the vertices labeled &icirc;object&#148;, &icirc;agent&#148;,
and &icirc;event&#148;. Subjects were asked to place an &icirc;X&#148;
in the triangle at the place which best described the phenomenological
properties of the stimuli presented.</FONT>
<P>
<FONT COLOR=#000000>The second and third questions were forced
choice. The second question asked the subject to again appraise
the stimuli; this time the subject had to make a forced choice
between the three. In the third question, subjects were asked
to rate the &icirc;intelligence&#148; or &icirc;potential intelligence&#148;
of the stimuli shown. This rating was given on a standard ten
point scale, in which &icirc;1&#148; represented no intelligence
and &icirc;10&#148; represented high intelligence. All of the
questions and instructions were given in either English or Japanese.
<BR>
</FONT>
<H2>DESIGN AND PROCEDURES</H2>
<P>
<FONT COLOR=#000000>Each subject was given written instructions
before the trial began. The instructions included definitions
of each type of phenomena. They also included sample answers to
the questions. The subjects were allowed to ask questions about
the instructions and experiment at this time.</FONT>
<P>
<FONT COLOR=#000000>The subjects were seated approximately four
feet in front of a large, wall-sized lenticular display. A reflective
marker was placed on their chin. The system was then calibrated
so that the subject&iacute;s head could be tracked by remote infrared
cameras. The lenticular display presented the stimuli in three
dimensional monochrome; the stimuli were stabilized so that the
subject could move his or her head and upper body to see different
perspectives.</FONT>
<P>
<FONT COLOR=#000000>Once the subject was comfortable with the
experimental configuration and the system was calibrated, the
lights were dimmed, and the experiment began. The trial proceeded
at the subject&iacute;s own pace. In each presentation, the subject
was exposed to a representation or stimuli for 15 seconds. At
the conclusion of the presentation, the subject completed the
three questions associated with it and signaled for the next presentation.
This sequence continued until all presentations were made in random
order. <BR>
</FONT>
<H2>RESULTS</H2>
<P>
<FONT COLOR=#000000>Preliminary results indicate that fully articulated
human forms were appraised as agents significantly more often
than other anthropomorphic forms and all of the other stimuli
presented F(3,14)=18.43, p&lt;.05. Subjects rated the intelligence
of the human forms to be significantly higher than either the
caricatures, t(17)=7.05, p&lt;.001, and t(17)=6.01, p&lt;.001,
or the Chernoff faces, t(17)=8.44, p&lt;.001, and t(17)=8.83,
p&lt;.001. </FONT>
<P>
<FONT COLOR=#000000>Within the human forms, the three dimensional
representations were significantly more likely to be appraised
as agents rather than objects. Appraised level of agency and intelligence
was found to be similar across the more symbolic caricatures and
Chernoff faces. However, all of the anthropomorphic representations,
including the more symbolic ones, were judged to be more intelligent
and capable of higher agency than the other stimuli presented
(e.g., geometric shapes, objects, etc.). The blinking human forms
were appraised to have significantly higher agency and to be more
intelligent than any of the other representations, including the
identical non-blinking forms. <BR>
</FONT>
<H2>DISCUSSION</H2>
<P>
<FONT COLOR=#000000>The designer wants the software entity to
be appraised with a certain level of agency and intelligence.
While human facial displays and anthropomorphic representations
may seem appropriate, the results indicate that these representations
are judged to inherently have a high degree of agency and intelligence.
Subtle behavioral displays (e.g., eye blinking) can have a great
effect on the user&iacute;s appraisal of these capabilities. </FONT>
<P>
<FONT COLOR=#000000>The designer of agent-based interfaces must
be careful to choose appropriate representations and behaviors.
These choices will have a dramatic effect on the user&iacute;s
judgment of the agent and on the trust which the user places upon
the agent. Unless the agent is capable of human-like actions and
decisions, then the designer may be wise to avoid human-like representations.
<BR>
</FONT>
<H2>ACKNOWLEDGEMENTS</H2>
<P>
<FONT COLOR=#000000>The authors wish to thank Fumio Kishino and
Nobuyoshi Terashima for providing funding and a laboratory where
this research could be conducted. <BR>
</FONT>
<H2>REFERENCES</H2>
<OL>
<LI>Maes, P. Agents that Reduce Work and Information Overload,
Communications of the ACM, 37, 7, 31-40. 
<LI>Kozierok, R. &amp; Maes, P. A Learning Interface Agent for
Scheduling Meetings, Proceedings of the 1993 International Workshop
on Intelligent User Interfaces, New York: ACM Press, 81-96. 
<LI>Laurel, B. Interface Agents: Metaphors with Character. In
B. Laurel (Ed.). The Art of Human-Computer Interface Design, Reading,
MA: Addison-Wesley Publishing Company, 1990.
<LI>Oren, T., et. al. Guides: Characterizing the Interface. In
B. Laurel (Ed.). The Art of Human-Computer Interface Design, Reading,
MA: Addison-Wesley Publishing Company, 1990.
<LI>Naas, C., et. al. Computers are Social Actors, Proceedings
of the 1994 Conference on Human Factors in Computing Systems (CHI
&euml;94), New York: ACM Press, 72-77.
</OL>
</BODY>
</HTML>
